{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "5e11590c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import *\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "f7d7f5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ZeroMask():\n",
    "    \"\"\"\n",
    "    when this class is initialized, it will will initilize a mask. When the instance is called an input \n",
    "    array the same shape as the mask will be multiplied with the mask and returned. The returned array will\n",
    "    be masked to 0 at indecies specified in the \"zero_indices\" input. \n",
    "    \n",
    "    Having this as a call able class, lets us repeativly use a mask multiple times in a cleanly abstracted way.\n",
    "    \"\"\"\n",
    "    def __init__(self, shape, zero_indices):\n",
    "        \"\"\"\n",
    "        inputs:\n",
    "            shape: shape of matrix, ei (channels, filters, kernals, x_dims, y_dims)\n",
    "            zero_indices: list of tuples that specify indexes to be masked to 0, ei [(row, col, channel, filter)]\n",
    "                if zero_indices is equal to [(r, col, ch, f)] then mask[r, col, ch, f] will be set to 0\n",
    "        instance variables\n",
    "        \"\"\"\n",
    "        self.mask = np.ones(shape)\n",
    "        for index in zero_indices:\n",
    "            self.mask[index] = 0.  \n",
    "    def __call__(self, arr):\n",
    "        assert arr.shape == self.mask.shape, \"Incorrect dims, mask shape: {}, arr shape{}\".format(self.mask.shape, arr.shape)\n",
    "        return self.mask * arr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "d6c40ead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0, 0, 0), (0, 0, 0, 1), (0, 0, 0, 2), (0, 0, 0, 3), (0, 2, 0, 0), (0, 2, 0, 1), (0, 2, 0, 2), (0, 2, 0, 3), (1, 0, 0, 0), (1, 0, 0, 1), (1, 0, 0, 2), (1, 0, 0, 3), (2, 0, 0, 0), (2, 0, 0, 1), (2, 0, 0, 2), (2, 0, 0, 3), (2, 2, 0, 0), (2, 2, 0, 1), (2, 2, 0, 2), (2, 2, 0, 3), (0, 0, 0, 4), (0, 0, 0, 5), (0, 0, 0, 6), (0, 0, 0, 7), (0, 2, 0, 4), (0, 2, 0, 5), (0, 2, 0, 6), (0, 2, 0, 7), (2, 0, 0, 4), (2, 0, 0, 5), (2, 0, 0, 6), (2, 0, 0, 7), (2, 1, 0, 4), (2, 1, 0, 5), (2, 1, 0, 6), (2, 1, 0, 7), (2, 2, 0, 4), (2, 2, 0, 5), (2, 2, 0, 6), (2, 2, 0, 7), (0, 0, 0, 8), (0, 0, 0, 9), (0, 0, 0, 10), (0, 0, 0, 11), (0, 1, 0, 8), (0, 1, 0, 9), (0, 1, 0, 10), (0, 1, 0, 11), (0, 2, 0, 8), (0, 2, 0, 9), (0, 2, 0, 10), (0, 2, 0, 11), (2, 0, 0, 8), (2, 0, 0, 9), (2, 0, 0, 10), (2, 0, 0, 11), (2, 2, 0, 8), (2, 2, 0, 9), (2, 2, 0, 10), (2, 2, 0, 11), (0, 0, 0, 12), (0, 0, 0, 13), (0, 0, 0, 14), (0, 0, 0, 15), (0, 2, 0, 12), (0, 2, 0, 13), (0, 2, 0, 14), (0, 2, 0, 15), (1, 2, 0, 12), (1, 2, 0, 13), (1, 2, 0, 14), (1, 2, 0, 15), (2, 0, 0, 12), (2, 0, 0, 13), (2, 0, 0, 14), (2, 0, 0, 15), (2, 2, 0, 12), (2, 2, 0, 13), (2, 2, 0, 14), (2, 2, 0, 15), (0, 1, 0, 16), (0, 1, 0, 17), (0, 1, 0, 18), (0, 1, 0, 19), (0, 2, 0, 16), (0, 2, 0, 17), (0, 2, 0, 18), (0, 2, 0, 19), (1, 2, 0, 16), (1, 2, 0, 17), (1, 2, 0, 18), (1, 2, 0, 19), (2, 1, 0, 16), (2, 1, 0, 17), (2, 1, 0, 18), (2, 1, 0, 19), (2, 2, 0, 16), (2, 2, 0, 17), (2, 2, 0, 18), (2, 2, 0, 19), (0, 2, 0, 20), (0, 2, 0, 21), (0, 2, 0, 22), (0, 2, 0, 23), (1, 0, 0, 20), (1, 0, 0, 21), (1, 0, 0, 22), (1, 0, 0, 23), (1, 2, 0, 20), (1, 2, 0, 21), (1, 2, 0, 22), (1, 2, 0, 23), (2, 0, 0, 20), (2, 0, 0, 21), (2, 0, 0, 22), (2, 0, 0, 23), (2, 2, 0, 20), (2, 2, 0, 21), (2, 2, 0, 22), (2, 2, 0, 23), (0, 0, 0, 24), (0, 0, 0, 25), (0, 0, 0, 26), (0, 0, 0, 27), (0, 1, 0, 24), (0, 1, 0, 25), (0, 1, 0, 26), (0, 1, 0, 27), (1, 0, 0, 24), (1, 0, 0, 25), (1, 0, 0, 26), (1, 0, 0, 27), (2, 0, 0, 24), (2, 0, 0, 25), (2, 0, 0, 26), (2, 0, 0, 27), (2, 1, 0, 24), (2, 1, 0, 25), (2, 1, 0, 26), (2, 1, 0, 27), (1, 0, 0, 28), (1, 0, 0, 29), (1, 0, 0, 30), (1, 0, 0, 31), (1, 2, 0, 28), (1, 2, 0, 29), (1, 2, 0, 30), (1, 2, 0, 31), (2, 0, 0, 28), (2, 0, 0, 29), (2, 0, 0, 30), (2, 0, 0, 31), (2, 1, 0, 28), (2, 1, 0, 29), (2, 1, 0, 30), (2, 1, 0, 31), (2, 2, 0, 28), (2, 2, 0, 29), (2, 2, 0, 30), (2, 2, 0, 31), (0, 0, 0, 32), (0, 0, 0, 33), (0, 0, 0, 34), (0, 0, 0, 35), (0, 1, 0, 32), (0, 1, 0, 33), (0, 1, 0, 34), (0, 1, 0, 35), (0, 2, 0, 32), (0, 2, 0, 33), (0, 2, 0, 34), (0, 2, 0, 35), (1, 0, 0, 32), (1, 0, 0, 33), (1, 0, 0, 34), (1, 0, 0, 35), (1, 2, 0, 32), (1, 2, 0, 33), (1, 2, 0, 34), (1, 2, 0, 35), (0, 0, 0, 36), (0, 0, 0, 37), (0, 0, 0, 38), (0, 0, 0, 39), (0, 1, 0, 36), (0, 1, 0, 37), (0, 1, 0, 38), (0, 1, 0, 39), (1, 0, 0, 36), (1, 0, 0, 37), (1, 0, 0, 38), (1, 0, 0, 39), (1, 2, 0, 36), (1, 2, 0, 37), (1, 2, 0, 38), (1, 2, 0, 39), (2, 1, 0, 36), (2, 1, 0, 37), (2, 1, 0, 38), (2, 1, 0, 39)]\n"
     ]
    }
   ],
   "source": [
    "def pattern_maker(filters, patterns, pattern_freq, kernel_size = (3,3)): #channels is limited to one here\n",
    "    channel = 0\n",
    "    assert filters == sum(pattern_freq)\n",
    "    zero_indices = []\n",
    "    filter_n = 0\n",
    "    for pattern, freq in zip(patterns, pattern_freq):\n",
    "        for i in range(kernel_size[0]):\n",
    "            for j in range(kernel_size[1]):\n",
    "                if pattern[i][j] == 0.:\n",
    "                    for _ in range(freq):\n",
    "                        zero_indices.append((i, j, channel, filter_n + _))\n",
    "        filter_n += freq\n",
    "        \n",
    "    return zero_indices\n",
    "\n",
    "patterns = [[[0, 1, 0], [0, 1, 1], [0, 1, 0]],\n",
    "            [[0, 1, 0], [1, 1, 1], [0, 0, 0]], \n",
    "            [[0, 0, 0], [1, 1, 1], [0, 1, 0]],\n",
    "            [[0, 1, 0], [1, 1, 0], [0, 1, 0]], \n",
    "            [[1, 0, 0], [1, 1, 0], [1, 0, 0]],\n",
    "            [[1, 1, 0], [0, 1, 0], [0, 1, 0]],\n",
    "            [[0, 0, 1], [0, 1, 1], [0, 0, 1]],\n",
    "            [[1, 1, 1], [0, 1, 0], [0, 0, 0]],\n",
    "           [[0, 0, 0], [0, 1, 0], [1, 1, 1]],\n",
    "           [[0, 0, 1], [0, 1, 0], [1, 0, 1]]]\n",
    "pattern_freq = [4]*10\n",
    "zero_indices = pattern_maker(4*10, patterns, pattern_freq)\n",
    "    \n",
    "print(zero_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "fdd8b404",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_func = ZeroMask(shape = (3, 3, 1, 40), zero_indices = zero_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "ef493ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "(ds_train, ds_test), ds_info = tfds.load(\n",
    "    'mnist',\n",
    "    split=['train', 'test'],\n",
    "    shuffle_files=True,\n",
    "    as_supervised=True,\n",
    "    with_info=True,\n",
    ")\n",
    "def normalize_img(image, label):\n",
    "  \"\"\"Normalizes images: `uint8` -> `float32`.\"\"\"\n",
    "  return tf.cast(image, tf.float32) / 255., label\n",
    "\n",
    "ds_train = ds_train.map(\n",
    "    normalize_img, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "ds_train = ds_train.cache()\n",
    "ds_train = ds_train.shuffle(ds_info.splits['train'].num_examples)\n",
    "ds_train = ds_train.batch(128)\n",
    "ds_train = ds_train.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "ds_test = ds_test.map(\n",
    "    normalize_img, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "ds_test = ds_test.batch(128)\n",
    "ds_test = ds_test.cache()\n",
    "ds_test = ds_test.prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "8af467fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#custom conv layer\n",
    "class IregConv2D(tf.keras.Model): # still needs to figure out backprop, keep kernal wieghts at 0!!.\n",
    "    def __init__(self, zero_mask, filters, kernel_size, *args, **kwargs):\n",
    "        super(IregConv2D, self).__init__()\n",
    "        self.conv = Conv2D(filters = filters, kernel_size = kernel_size, *args, **kwargs)\n",
    "        self.zero_mask = zero_mask\n",
    "        \n",
    "    def call(self, x):\n",
    "        return self.conv(x)\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        super(IregConv2D, self).build(input_shape)\n",
    "        weights = self.conv.get_weights()\n",
    "        weights[0] = self.zero_mask(weights[0]) # set weights to 0 here\n",
    "        self.conv.set_weights(weights)\n",
    "        \n",
    "    def get_conv(self):\n",
    "        return self.conv\n",
    "    \n",
    "    \n",
    "class TestNet(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(TestNet, self).__init__()\n",
    "        self.conv = IregConv2D(mask_func, filters = 40, kernel_size = (3, 3), activation = 'relu')\n",
    "        self.flatten = Flatten()\n",
    "        self.dense = Dense(32, activation = 'relu')\n",
    "        self.head = Dense(10, activation = 'softmax')\n",
    "    \n",
    "    def call(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.dense(x)\n",
    "        x = self.head(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "21b9cda2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.keras.Input(shape = (28, 28))\n",
    "model = TestNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "e3fac359",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad(model, inputs, targets):\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss_value = loss(model, inputs, targets, training=True)\n",
    "    return loss_value, tape.gradient(loss_value, model.trainable_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "6422b314",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "def loss(model, x, y, training):\n",
    "    # training=training is needed only if there are layers with different\n",
    "    # behavior during training versus inference (e.g. Dropout).\n",
    "    y_ = model(x, training=training)\n",
    "\n",
    "    return loss_object(y_true=y, y_pred=y_)\n",
    "optimizer = Adam(learning_rate = .01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "1d007e05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 000: Loss: 0.244, Accuracy: 93.995%\n",
      "Epoch 001: Loss: 0.069, Accuracy: 98.640%\n",
      "Epoch 002: Loss: 0.044, Accuracy: 99.243%\n",
      "Epoch 003: Loss: 0.034, Accuracy: 99.510%\n",
      "Epoch 004: Loss: 0.029, Accuracy: 99.617%\n"
     ]
    }
   ],
   "source": [
    "train_loss_results = []\n",
    "train_accuracy_results = []\n",
    "\n",
    "num_epochs = 5\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss_avg = tf.keras.metrics.Mean()\n",
    "    epoch_accuracy = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "    \n",
    "    # Training loop - using batches of 32\n",
    "    for x, y in ds_train:\n",
    "        # Optimize the model\n",
    "        loss_value, grads = grad(model, x, y)\n",
    "        grads[0] = mask_func(grads[0]) ###this is the important part here!!, needs to become robust\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "        # Track progress\n",
    "        epoch_loss_avg.update_state(loss_value)  # Add current batch loss\n",
    "        epoch_accuracy.update_state(y, model(x, training=True))\n",
    "\n",
    "    # End epoch\n",
    "    train_loss_results.append(epoch_loss_avg.result())\n",
    "    train_accuracy_results.append(epoch_accuracy.result())\n",
    "\n",
    "    print(\"Epoch {:03d}: Loss: {:.3f}, Accuracy: {:.3%}\".format(epoch,\n",
    "                                                                epoch_loss_avg.result(),\n",
    "                                                                epoch_accuracy.result()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b666a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f291b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9dff87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce89555",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b58cde8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9b2253",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
